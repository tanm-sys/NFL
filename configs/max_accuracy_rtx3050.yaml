# ============================================================================
# üèÜ RMSE OPTIMIZED - FITS RTX 3050 4GB
# ============================================================================
# NFL Big Data Bowl 2026 - Evaluation Metric: RMSE
# Tested: 9.6M params, Peak VRAM 2.1GB (fits comfortably in 4GB)
#
# RMSE = sqrt(mean((pred - target)^2))

experiment_name: "nfl_rmse_optimized"
description: "RMSE-optimized model for NFL Big Data Bowl 2026"

# ============================================================================
# DATA - FULL DATASET
# ============================================================================
data_dir: "."
weeks: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
radius: 25.0              # Good context coverage
future_seq_len: 10
history_len: 5

# ============================================================================
# MODEL ARCHITECTURE - OPTIMIZED FOR 4GB VRAM
# ============================================================================
# Tested: 9.6M params, Peak VRAM 2.1GB
input_dim: 9
hidden_dim: 256           # Optimal for 4GB
num_gnn_layers: 6         # 6 layers (proven effective)
num_decoder_layers: 4
heads: 8                  # 8 attention heads
dropout: 0.10
droppath_rate: 0.15

# Probabilistic Multi-Modal
probabilistic: true
num_modes: 12             # 12 modes for good minRMSE

# Advanced Components
use_scene_encoder: true
temporal_encoder_type: "hybrid"
use_goal_decoder: true
use_social_pooling: true

# ============================================================================
# TRAINING - RMSE OPTIMIZED
# ============================================================================
batch_size: 24             # Good balance
accumulate_grad_batches: 8  # Effective batch = 192
learning_rate: 0.0001      # Standard rate
max_epochs: 150
min_epochs: 50

# Optimizer
optimizer: "adamw"
weight_decay: 0.05
betas: [0.9, 0.999]

# LR Scheduler
lr_scheduler: "cosine_warmup"
warmup_epochs: 10
warmup_start_lr: 1.0e-06
min_lr: 1.0e-08

# ============================================================================
# LOSS WEIGHTS - RMSE FOCUSED
# ============================================================================
# PRIMARY: RMSE Loss (competition metric)
use_rmse_loss: true
rmse_weight: 2.0          # PRIMARY LOSS

# Secondary losses
trajectory_weight: 0.5    # Reduced - RMSE is primary
velocity_weight: 0.6
acceleration_weight: 0.4
collision_weight: 0.20
coverage_weight: 0.5

# ============================================================================
# SOTA LOSSES
# ============================================================================
use_social_nce: true
social_nce_weight: 0.20
social_nce_temperature: 0.05

use_contrastive_loss: true
contrastive_weight: 0.15

# WTA with RMSE-based selection
use_wta_loss: true
wta_k_best: 3
wta_weight: 0.8

use_diversity_loss: true
diversity_weight: 0.05
diversity_min_distance: 2.5

use_endpoint_focal: true
endpoint_focal_weight: 0.35
endpoint_focal_gamma: 3.0

# MinRMSE Loss
use_min_rmse_loss: true
min_rmse_weight: 1.0

# ============================================================================
# REGULARIZATION
# ============================================================================
gradient_clip_val: 0.5
use_augmentation: true
use_huber_loss: false
label_smoothing: 0.05
use_ema: true
ema_decay: 0.999

# ============================================================================
# HARDWARE - RTX 3050 4GB (VERIFIED)
# ============================================================================
precision: "16-mixed"
accelerator: "gpu"
devices: 1
benchmark: true
deterministic: false
num_workers: 0

# Memory
in_memory_cache_size: 150
persist_cache: true
cache_dir: "cache/finetune/train"

# ============================================================================
# CALLBACKS
# ============================================================================
early_stopping_patience: 25
early_stopping_min_delta: 0.0001
monitor_metric: "val_rmse"
monitor_mode: "min"
save_top_k: 10
save_last: true

# SWA
swa_enabled: true
swa_epoch_start: 0.70
swa_lrs: 1.0e-06
swa_annealing_epochs: 15

# ============================================================================
# TARGET METRICS (RMSE)
# ============================================================================
target_val_rmse: 0.40
target_val_min_rmse: 0.30
target_val_ade: 0.28
target_val_fde: 0.45

# ============================================================================
# VERIFIED SPECS
# ============================================================================
# Model: 9.6M parameters
# Peak VRAM: 2.1 GB (with batch=24)
# Fits: RTX 3050 4GB ‚úÖ
# Speed: ~2 it/s with cache
