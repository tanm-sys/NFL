# ============================================================================
# MAXIMUM QUALITY + FAST TRAINING CONFIGURATION
# ============================================================================
# Best possible accuracy at maximum speed for RTX 3050 Laptop GPU
# Your previous run achieved val_ade = 0.566 yards - targeting < 0.5

experiment_name: "nfl_best_quality"
description: "Highest quality model with optimized speed"

# Data Configuration
data:
  data_dir: "."
  weeks: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  validate_data: false
  radius: 20.0
  future_seq_len: 10

# Model Architecture - MAXIMUM QUALITY
model:
  input_dim: 7
  hidden_dim: 192            # Larger for better representations
  num_gnn_layers: 8          # Deeper network
  heads: 8                   # More attention heads
  dropout: 0.12              # Balanced regularization
  probabilistic: false
  num_modes: 6
  use_scene_encoder: true

# Training Configuration - QUALITY + SPEED
training:
  batch_size: 96             # Sweet spot for RTX 3050 (4GB)
  learning_rate: 0.0008      # Slightly lower for larger model
  max_epochs: 200            # More epochs for convergence
  min_epochs: 30
  num_workers: 4
  accumulate_grad_batches: 1

# Optimization
optimizer:
  type: "adamw"
  weight_decay: 0.00015      # Slightly more regularization
  betas: [0.9, 0.999]
  eps: 1.0e-08

# Learning Rate Scheduler - Cosine with Warmup
lr_scheduler:
  type: "cosine_warmup"
  warmup_epochs: 5
  min_lr: 1.0e-07

# Loss Weights - Multi-task Learning
loss_weights:
  trajectory: 1.0
  velocity: 0.35             # Smooth trajectories
  acceleration: 0.15         # Physically plausible
  collision: 0.05
  coverage: 0.5

# Regularization - QUALITY FOCUSED
regularization:
  gradient_clip_val: 1.0
  use_augmentation: true     # Critical for generalization
  use_huber_loss: true       # Robust to outliers
  huber_delta: 1.0
  label_smoothing: 0.03      # Slight smoothing

# Hardware - MAXIMUM GPU UTILIZATION
hardware:
  precision: "16-mixed"      # FP16 for speed + larger batches
  accelerator: "gpu"
  devices: 1
  strategy: "auto"

# Callbacks - QUALITY CHECKPOINTING
callbacks:
  early_stopping:
    enabled: true
    patience: 20             # More patience for deep model
    min_delta: 0.0003
    monitor: "val_ade"
    mode: "min"
    
  model_checkpoint:
    save_top_k: 5            # Keep more checkpoints
    monitor: "val_ade"
    mode: "min"
    save_last: true

# Logging
logging:
  use_mlflow: false
  use_wandb: false
  use_tensorboard: true
  log_every_n_steps: 25

# Paths
paths:
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
  output_dir: "./outputs"

# Reproducibility - BALANCED
reproducibility:
  seed: 42
  deterministic: false       # Speed boost
  benchmark: true            # cuDNN autotuning

# Production
production:
  enable_profiling: false
  export_onnx: true
  export_torchscript: true
  save_config: true

# Target Metrics (Competition-winning targets)
thresholds:
  target_val_ade: 0.45       # Aggressive < 0.5 yards
  target_val_fde: 0.80
  target_val_miss_rate: 0.08
  target_val_cov_acc: 0.92
