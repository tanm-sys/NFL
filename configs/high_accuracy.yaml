# ============================================================================
# OPTIMIZED QUALITY CONFIG - ANTI-OVERFITTING + HARDWARE OPTIMIZED
# ============================================================================
# Based on analysis: Previous run showed overfitting signs at epoch 21
# (val_ade increased 0.566 â†’ 0.576). This config prevents that.
#
# RTX 3050 (4GB VRAM) Hardware Optimizations Applied.

experiment_name: "nfl_optimized_quality"
description: "Best quality without overfitting - hardware optimized"

# Data Configuration
data:
  data_dir: "."
  weeks: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  validate_data: false
  radius: 20.0
  future_seq_len: 10

# Model Architecture - BALANCED (proven effective, less overfitting risk)
model:
  input_dim: 7
  hidden_dim: 128            # Reduced from 192 - less overfitting
  num_gnn_layers: 6          # Reduced from 8 - proven effective
  heads: 8
  dropout: 0.18              # Increased from 0.12 - stronger regularization
  probabilistic: false
  num_modes: 6
  use_scene_encoder: true

# Training - OPTIMIZED FOR RTX 3050
training:
  batch_size: 128            # Larger batch fits with hidden_dim=128 + FP16
  learning_rate: 0.001
  max_epochs: 100            # Reduced from 200 - prevents late overfitting
  min_epochs: 25
  num_workers: 4
  accumulate_grad_batches: 1

# Optimization - STRONGER REGULARIZATION
optimizer:
  type: "adamw"
  weight_decay: 0.0003       # Doubled - prevents overfitting
  betas: [0.9, 0.999]
  eps: 1.0e-08

# Learning Rate Scheduler
lr_scheduler:
  type: "cosine_warmup"
  warmup_epochs: 5
  min_lr: 1.0e-07

# Loss Weights
loss_weights:
  trajectory: 1.0
  velocity: 0.35
  acceleration: 0.15
  collision: 0.05
  coverage: 0.5

# Regularization - ANTI-OVERFITTING
regularization:
  gradient_clip_val: 1.0
  use_augmentation: true     # Data augmentation ON
  use_huber_loss: true       # Robust loss
  huber_delta: 1.0
  label_smoothing: 0.1       # Increased - prevents overconfidence

# Hardware - MAXIMUM GPU UTILIZATION
hardware:
  precision: "16-mixed"      # FP16 for speed + memory
  accelerator: "gpu"
  devices: 1
  strategy: "auto"

# Callbacks - EARLIER STOPPING
callbacks:
  early_stopping:
    enabled: true
    patience: 15             # Reduced from 20 - catches overfitting earlier
    min_delta: 0.0005
    monitor: "val_ade"
    mode: "min"
    
  model_checkpoint:
    save_top_k: 5
    monitor: "val_ade"
    mode: "min"
    save_last: true

# Logging
logging:
  use_mlflow: false
  use_wandb: false
  use_tensorboard: true
  log_every_n_steps: 25

# Paths
paths:
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
  output_dir: "./outputs"

# Reproducibility - SPEED MODE
reproducibility:
  seed: 42
  deterministic: false       # Faster
  benchmark: true            # cuDNN autotuning

# Production
production:
  enable_profiling: false
  export_onnx: true
  export_torchscript: true
  save_config: true

# Target Metrics
thresholds:
  target_val_ade: 0.50
  target_val_fde: 0.90
  target_val_miss_rate: 0.10
  target_val_cov_acc: 0.90
